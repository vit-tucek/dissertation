\chapter{Lie algebras and their modules}

In this chapter we fix some notation and review several structural results about Lie algebras. First we start with some basic definitions concerning a Lie algebra $\lie{g}$ over a field $\k$ of real or complex numbers.

\medskip


Let $\lie{g}^{1} = \lie{g}$ and define inductively the so called \emph{lower central series} of $\lie{g}$ by $\lie{g}^{k+1} = [\lie{g},\lie{g}^{k}]$.  A subalgebra $\lie{n}$ of $\lie{g}$ is called \emph{nilpotent} if $\lie{n}^{k} = 0$ for some $k\in\N$.

Let $\lie{g}^{(1)} = \lie{g}$ and define inductively the so called \emph{derived series} of $\lie{g}$ by $\lie{g}^{(k+1)} = [\lie{g}^{(k)},\lie{g}^{(k)}]$.  A subalgebra $\lie{b}$ of $\lie{g}$ is called \emph{solvable} if $\lie{b}^{(k)} = 0$ for some $k\in\N$. A \emph{Borel subalgebra} $\lie{b}$ of $\lie{g}$ is any maximal solvable subalgebra of $\lie{g}$.


We denote by $\ad(X)$ the Lie algebra homomorphism $\lie{g}\to \lie{g}$ given by $Y\mapsto [X,Y]$. This is the \emph{adjoint representation} of $\lie{g}$.

A  Lie algebra $\lie{g}$ is said to be \emph{semisimple} if it has no nonzero solvable ideal and it is called \emph{simple} if $\lie{g} = [\lie{g},\lie{g}]$ and the only ideals of $\lie{g}$ are $0$ and $\lie{g}$. Any semisimple Lie algebra is a direct sum of simple Lie algebras. An \emph{semisimple element} $X$ of $\lie{g}$ is an element of $\lie{g}$ such that $\ad X: \lie{g} \to \lie{g}$ is diagonalizable.

A \emph{Cartan subalgebra} of a complex Lie algebra $\lie{g}$ is a maximal commutative subalgebra $\lie{h}$ of $\lie{g}$ consisting of semisimple elements. For a real Lie algebra $\lie{g}_\R$ we define its Cartan subalgebra $\lie{h}_\R$ as such that its complexification $\lie{h}_\C$ is a Cartan subalgebra of the complexification of $\lie{g}_\R$.

A \emph{reductive} Lie algebra $\lie{g}$ is a Lie algebra that decomposes as $\lie{g} = \lie{z(g)} \oplus \lie{g}_{ss}$, where $\lie{z(g)}$ is the center of $\lie{g}$ and the algebra $\lie{g}_{ss} = [\lie{g},\lie{g}]$ is the \emph{semisimple part} of $\lie{g}$. Of course, as its name suggest, the algebra $\lie{g}_{ss}$ is semisimple.

Let $\lie{g}$ be a real or complex Lie algebra let $B$ be a bilinear form $\lie{g}\otimes \lie{g} \to \k$. We say that $B$ is invariant if all $\ad X$, $X\in\lie{g}$ are skew-symmetric operators relative to $B$, i.e.
\[
 B([X,Y],Z) = -B(Y,[X,Z]), \quad \forall X,Y,Z \in \lie{g}.
\]
The most important invariant form is the so called \emph{Killing form} which we will denote $B$ and which exists for any Lie algebra $\lie{g}$. It is defined by
\[
 B(X,Y) = \tr(\ad(X) \circ ad(Y)).
\]
If $\phi:\lie{g} \to \lie{g}$ is any automorphism of the Lie algebra $\lie{g}$, then by definition $\ad(X) \circ \phi = \phi \circ \ad(X)$ for any $X\in\lie{g}$. This implies
\[
 \ad(\phi(X)) \circ \ad(\phi(Y)) = \phi \circ \ad(X)\circ\ad(Y)\circ\phi^{-1}
\]
and thus $B(\phi(X),\phi(Y)) = B(X,Y)$. The Cartan criterion states that a Lie algebra $\lie{g}$ is semisimple if and only if the Killing form $B$ is nondegenerate.

\subsection{Complex Lie algebras}

Let $\lie{g}$ be a complex semisimple Lie algebra and choose a Cartan subalgebra $\lie{h} \leq \lie{g}$. Any two Cartan subalgebras of $\lie{g}$ are conjugate by an inner automorphism of $\lie{g}$. The roots $\roots$ of $(\lie{g},\lie{h})$ are linear functionals $\alpha: \lie{h} \to \C$ such that the corresponding \emph{root space} $\lie{g}_\alpha = \{ X\in G \,|\,\forall H\in \lie{h}: [H,X] = \alpha(H) X \}$ is nonempty. In other words, roots are the nontrivial weights of the adjoint representation $\ad:\lie{g}\to\lie{g}$. The roots form a finite subset $\roots \subset \lie{h}^*$ and we have the \emph{root space decomposition}
\[
 \lie{g} = \lie{h} \oplus \sum_{\alpha \in \roots} \lie{g}_\alpha.
\]

If $X\in\lie{g}_\alpha$ and $Y\in\lie{g}_\beta$, then $B(X,Y) = 0$ unless $\alpha = -\beta$. Thus the Killing form induces a nondegenerate pairing on $\lie{g}_\alpha \otimes \lie{g}_{-\alpha}\to \C$. The restriction of $B$ to $\lie{h}$ is nondegenerate and, in particular, for each linear functional $\lambda \in \lie{h}^*$, there is a unique
 element $\widetilde{H_\lambda} \in \lie{h}$ such that $\lambda(H) = B(H,H_\lambda)$ for all $H\in\lie{h}$. We can define the bilinear form $(\, , \,)$ on $\lie{h}^*$ by
\[
 (\lambda,\mu) = B(\widetilde{H_\lambda}, H_\mu).
\]
The restriction of $(\, , \, )$ to the real span of $\roots$ is positive definite (and in particular has real values).

Let us summarize the properties of $\roots$
\begin{enumerate}
 \item For any $\alpha \in \roots$ the only nontrivial complex multiple of $\alpha$ that is also a root is $-\alpha$, i.e.
	\[ z \alpha \in \roots, \quad z\in \C \Longleftrightarrow z \in \{ 1, -1 \}. \]
 \item The roots spaces $\lie{g}_{-\alpha}$ are one-dimensional and the subspace spanned by $\lie{g}_{-\alpha}, \lie{g}_\alpha$ and $[\lie{g}_{-\alpha}, \lie{g}_\alpha]$ is a Lie subalgebra isomorphic to $\lie{sl}(2,\C)$.
 \item For $\alpha, \beta \in \roots$, $\beta \neq -\alpha$ we have
 \[
  [\lie{g}_\alpha,\lie{g}_\beta] = \begin{cases}
				      \lie{g}_{\alpha + \beta} & \text{ if } \alpha + \beta \in \roots \\
				        0 & \text{otherwise}.
                                  \end{cases}
 \]
 \item Let $\alpha, \beta \in \roots$ with $\beta \neq \pm \alpha$ and $z\in\C$. A functional $\alpha + z\beta$ can be a root if and only if $z\in\Z$. The set of such roots form an unbroken chain
 \[ \beta - p\alpha, \beta -(p-1)\alpha, \ldots, \beta + (q-1)\alpha, \beta +q\alpha, \]
       where $p,q\geq 0$ and $p-q = \frac{2(\beta,\alpha)}{(\alpha,\alpha)}$. 
\end{enumerate}

For a root $\alpha \in \roots$ we define the \emph{coroot} $H_\alpha$ as
\[
 H_\alpha = \frac{2}{(\alpha,\alpha)}\widetilde{H_\alpha}.
\]
A nonzero vectors in $\lie{g}_\alpha$ are called a \emph{root vectors}. From the properties of $\roots$ follows that we can always find root vectors $E_\alpha \in \lie{g}_\alpha$, $F_\alpha \in \lie{g}_{-\alpha}$ such that the triple $E_\alpha, F_\alpha, H_\alpha$ satisfies the canonical $\sl(2)$ relations
\[
 [E,F] = H, \quad [H,E] = 2E, \quad [H,F] = -2F
\]

Choose a basis $v_1, \ldots, v_r$ of $\lie{h}$ and define a linear functional $\lambda\in\lie{h}^*$ to be \emph{positive} if there is an index $j$ such that $\lambda(v_i) = 0$ for $i<j$ and $\lambda(v_j) > 0$. The \emph{positive roots} $\roots^+$ are then the roots which are positive and we obtain a disjoint union $\roots = \roots^+ \cup \roots^-$. The \emph{negative roots}  $\roots^-$ are defined as $-\roots^+$ and we will write $\alpha > 0$ or $\alpha < 0$ to indicate whether the root is positive or negative. By $\sroots$ we will denote the set of \emph{simple roots} associated with $\roots$ and the notion of positivity for $\lie{h}^*$. The simple roots are define as the set of those positive roots, which cannot be written as a sum of positive roots. The set of simple roots $\sroots$ forms a basis of $\lie{h}^*$. Alternatively, one can start with a subset $\sroots$ of $\roots$ that form a basis of $\lie{h}^*$ and declare it to be the set of simple roots. The positive and negative roots are then obtained as 
positive or negative linear combinations of elements of $\sroots$.

Let $\sroots=\{ \alpha_1, \ldots, \alpha_r \}$ be a system of simple roots for $(\lie{g},\lie{h})$. The \emph{Cartan matrix} is defined as
\[
 a_{ij} =\frac{2(\alpha_i,\alpha_j)}{(\alpha_i,\alpha_i)}.
\]
A \emph{Dynking diagram} is defined as a graph with vertex for each simple root and $i$th and $j$th vertex are joined by $a_{ij}a_{ji}$ many edges. If a two joined vertices correspond to roots of different lengths, one orients the edges by arrow pointing from the longer root to the shorter one.

% Sometimes it is convenient for computations to choose a suitable basis. For a simple roots $\sroots = \{ \alpha_1, \ldots, \alpha_n \}$ choose elements $E_i$  in the root spaces $\lie{g}_{\alpha_i}$ and $F_i \in \lie{g}_{-\alpha_i}$ such that $[E_i,F_i] = \frac{2}{(\alpha_i,\alpha_i)}$. This means that $H_i =[E_i,F_i]$ satisfies $\alpha_i(H_i)=2$ and hence $E_i,F_i,H_i$ is a $\lie{sl}(2,\C)$-triple. The elements of $\{H_i, E_i, F_i : i=1,\ldots, n \}$ are called \emph{Chevalley-Serre} generators and they satisfy the so called \emph{Chevalley-Serre relations}:
% \begin{align*}
%  [E_i, F_j] &= \delta_{i,j}H_i \\
%  [H_i, E_j] &= a_{ij}E_j \\
%  [H_i, F_j] &= -a_{ij}F_j \\
%  \ad(E_i)^{-a_{ij}+1} E_j &= 0 \\
%  \ad(F_i)^{-a_{ij}+1} F_j &= 0 \text{ for } i\neq j.
% \end{align*}



\emph{representation, dominant, integral} %TODO

For a root $\alpha \in \roots$ we define \emph{root reflection} $s_\alpha$ as
\[
 s_\alpha: \phi \mapsto \phi - \frac{2(\phi,\alpha)}{(\alpha,\alpha)}\alpha.
\] It is a reflection with respect to the hyperplane orthogonal to $\alpha$ on the Euclidean space formed by the real span of $\roots$ endowed with the restriction of $(\, , \,)$. The set of roots is preserved under root reflections \( s_\alpha(\roots) = \roots\) and the group $W(\roots)$ generated by these reflections is known under the name \emph{Weyl group}. In fact, it is sufficient to take reflections with respect to simple roots to generate the whole Weyl group, i.e. $W(\sroots) = W(\roots)$.

\emph{Bruhat order}%TODO

\subsection{Borel and parabolic subalgebras}

Given a complex Lie algebra $\lie{g}$ with a chosen Cartan subalgebra $\lie{h}$ and a system of positive roots $\roots^+$ we get a \emph{Cartan decomposition} (\emph{triangluar decomposition}) as
\[
 \lie{g} = \lie{n}^- \oplus \lie{h} \oplus \lie{n}, \quad \text{where } \lie{n} = \bigoplus_{\alpha \in \roots^+} \lie{g}_\alpha \text{ and } \lie{n}^- = \bigoplus_{\alpha \in \roots^-} \lie{g}_\alpha.
\]
The Lie subalgebras $\lie{n}$, $\lie{n}^-$ are nilpotent and $\lie{n}^-$ is called the \emph{opposite} Lie subalgebra to $\lie{n}$. The subalgebra $\lie{b} = \lie{h}\oplus \lie{n}$ is the \emph{standard Borel subalgebra} and we will denote by $\lie{b}^-$ the opposite  Borel subalgebra. It is clear from the Cartan decomposition that $\lie{b}\cap\lie{b}^- = \lie{h}$. All Borel subalgebras are conjugated by inner automorphism to the standard Borel subalgebra.

A \emph{parabolic subalgebra} $\lie{p}$ of $\lie{g}$ is a subalgebra that contains a Borel subalgebra, \emph{standard parabolic subalgebra} is then a subalgebra that contains the standard Borel subalgebra. All parabolic subalgebras are conjugated by inner automorphism to a standard parabolic subalgebra.

Any parabolic subalgebra $\lie{p}$ has a decomposition
\[
 \lie{p} = \lie{l} \oplus \lie{u}
\]
into its Levi part $\lie{l}$ and nilpotent part $\lie{u}$. The Levi part is a reductive Lie subalgebra of $\lie{g}$.

Standard parabolic subalgebras are classified by subset of simple roots (Proposition 3.2.1 of \cite{cap_parabolic_2009}). To a standard parabolic subalgebra $\lie{p}$ we assign the subset \[\Sigma_\lie{p} = \{ \alpha\in\sroots : \lie{g}_{-\alpha}\nsubseteq \lie{p} \}.\] Conversely, the standard parabolic subalgebra $\lie{p}_\Sigma$ corresponding to a subset $\Sigma \subseteq \sroots$ is the sum of the standard Borel subalgebra $\lie{b}$ and all negative root spaces corresponding to roots $\roots_\Sigma$ which can be written as a linear combination of elements of $\sroots \setminus \Sigma$
\[
 \lie{p}_\Sigma = \lie{b} \oplus \sum_{\alpha \in \roots_\Sigma} \lie{g}_{-\alpha}.
\]
In particular, given $\Sigma \subset \sroots$ we get
\[
 \lie{l} = \lie{h} \oplus \sum_{\alpha \in \roots_\Sigma} \lie{g}_\alpha, \quad \lie{u} = \sum_{\alpha \in \roots^+ \setminus \roots_\Sigma} \lie{g}_{\alpha}.
\]

For $\Sigma \subseteq \Sigma' \subseteq \sroots$ we have $\lie{p}_{\Sigma'} \leq \lie{p}_\Sigma \leq \lie{g}$ and the two extreme choices $\Sigma = \emptyset$, $\Sigma = \sroots$ lead to $\lie{p}= \lie{g}$ and $\lie{p} = \lie{b}$ respectively.

\emph{opposite parabolic} subalgebra %TODO

It is convenient to denote parabolic subalgebras by Dynkin diagrams with crossed roots. Namely, the standard parabolic subalgebra $\lie{p}_\Sigma$ of $(\lie{g},\roots^+)$ is denoted by the Dynkin diagram of $\lie{g}$ where the nodes corresponding to $\Sigma$ are represented by crosses instead of dots. By erasing of these crossed nodes one obtains the Dynkin diagram of the semisimple part of $\lie{l}$ and the crossed nodes correspond precisely to the generators of the center of $\lie{l}$.

The following lemma (whose proof can be found in \cite{cap_parabolic_2009}) shows that the parabolic subalgebras are equivalent to gradings of the lie algebra $\lie{g}$.
\begin{lemma}
There is a bijective correspondence between parabolic subalgebras of $\lie{g}$ and gradings $\lie{g}=\oplus_{i=-k}^k \lie{g}_i$ of $\lie{g}$.

	Given $\Sigma\subset\sroots$, the set $\lie{g}_i$ ($i\neq 0)$ is defined to be $\oplus_{\phi\in A_i} \lie{g}_\phi$, where $A_i$ contains elements $\phi=\sum_{\alpha_j\in\sroots} c_j \alpha_j$ such that $\sum_{\{j:\alpha_j\in\Sigma\}} c_j=i$, and $\lie{g}_0=\lie{h}\oplus_{\phi\in A_0} \lie{g}_\phi$.

	Given a grading $\oplus_j \lie{g}_j$, the parabolic subalgebra is then $\lie{p}=\oplus_{j\lie{g}eq 0}\lie{g}_j$.
\end{lemma}

\begin{lemma}[Proposition 3.1.2 of \cite{cap_parabolic_2009}]
	Let $\lie{g}=\lie{g}_{-k}\oplus\cdots \lie{g}_k$ be a $|k|$-graded semisimple Lie algebra over $\k=\R$ or $\C$ and let $B:\lie{g}\otimes \lie{g}\to \k$ be a nondegenerate invariant bilinear form. Then we have:
	\begin{enumerate}
	 \item There is a unique element $E \in \lie{g}$, called the \emph{grading element}, such that \([E,X] = jX\) for all $X \in \lie{g}_j$. The element $E$ lies in the center of the subalgebra $\lie{g}_0 \leq \lie{g}$.
	 \item The $|k|$-grading on $\lie{g}$ induces a $|k_i|$-grading for some $k_i\leq k$ on each ideal $s\subseteq \lie{g}$. In particular, $\lie{g}$ is a direct sum of $|k_i|$-graded simple Lie algebras, where $k_i\leq k$ for all $i$ and $k_i=k$ for at least one $i$.
	 \item The isomorphism $\lie{g} \to \lie{g}^*$ provided by $B$ is compatible with the filtration and the grading of $\lie{g}$. In particular, $B$ induces dualities of $\lie{g}_0$-modules between $\lie{g}_i$ and $\lie{g}_{-i}$ and the filtration component $\lie{g}^i$ is exactly the annihilator (with respect to $B$) of $\lie{g}^{-i+1}$. Hence, $B$ induces a duality of $\lie{p}$-modules between $\lie{g}/\lie{g}^{-i+1}$ and $\lie{g}^i$, and in particular between $\lie{g}/\lie{p}$ and $\lie{p}_+$.  
	 \item For $i<0$ we have $[\lie{g}_{i+1},\lie{g}_{-1}] = \lie{g}_i$. If no simple ideal of $\lie{g}$ is contained in $\lie{g}_)$, then this also holds for $i=0$.
	 \item Let $A\in\lie{g}_i$ with $i>0$ be an element such that $[A,X]=0$ for all $X\in\lie{g}_{-1}$. Then $A=0$. If no simple ideal of $\lie{g}$ is contained in $\lie{g}_)$, then this also holds for $i=0$.
	\end{enumerate}
\end{lemma}

In particular, the Killing form $B$ has the following anti-diagonal block matrix form with respect to the decomposition $\lie{g}=\lie{g}_{-k}\oplus\cdots \lie{g}_k$
\[
 B = \begin{pmatrix}
      0 & \cdots & B_{k,-k} \\
      \vdots &  \ddots & \vdots \\
      B_{-k,k} & \cdots&0
     \end{pmatrix},
\]
where $B_{i,j}$ denote the restriction of $B$ to $\lie{g}_i\otimes \lie{g}_j$.



Classification of Hermitian symmetric pairs. We treat this material from the view of representation (or Lie) theory as in \cite{knapp}. Geometric treatment of Hermitian symmetric spaces is presented for example in \cite{helgason}.

\subsection{Real Lie algebras}

The \emph{complexification} of a real reducitve Lie algebra $\lie{g}_0$ is define as $\lie{g} = \lie{g}_0\otimes_\R \C$. With Lie bracket defined naturally by complex linear extension as follows
\[
 [A\otimes z, B\otimes w] = [A,B]\otimes zw.
\]
As a real vector space we have isomorphism $\lie{g} \simeq \lie{g}_0 \oplus \imath \lie{g}_0$ defined by $X\otimes (a+\imath b) \mapsto aX \oplus \imath bX$. Writing elements $Z,Z'\in\lie{g}$ as $Z = X + \imath Y$ $Z'=X'+\imath Y'$ we get \[[Z,Z'] = [X,X'] - [Y,Y'] + \imath \left( [X,Y'] + [X',Y]\right).\]

A \emph{real form} of a complex Lie alebra $\lie{g}$ is a real Lie algebra $\lie{g}_0$ such that $\lie{g}$ is the complexification of $\lie{g}_0$. A complex Lie algebra usually has many nonisomorphic real forms. For a complexification $\lie{g}$ of $\lie{g}_0$ we will denote by $\sigma$ the conjugation of $\lie{g}$ with respect to the real form $\lie{g}_0$.

\begin{example}
 The complexification of the classical Lie algebra of trace-free real matrices $\lie{sl}(n,\R)$ is naturally isomorphic to the Lie algebra of trace-free complex matrices $\lie{sl}(n,\C)$. Anoter real form of $\lie{sl}(n,\C)$ is for example the algebra of trace-free skew Hermitian  matrices  $\lie{su}(n)$. %TODO
\end{example}

An \emph{involution} of a Lie algebra $\lie{g}$ is Lie algebra homomorphism $\lie{g}\to\lie{g}$ which squares to identity. An involution $\theta$ of a real semisimple Lie algebra $\lie{g}_0$ is called \emph{Cartan involution} if the symmetric bilinear form $B_\theta(X,Y) = -B(X,\theta Y)$ is postivive definite. We will denote the complex linear extension of $\theta$ to the complexification of $\lie{g}_0$ by the same symbol and we will still call it the Cartan involution. Any real semisimple Lie algebra has a Cartan involution and it is unique up to inner automorphism.

\begin{example}
  Cartan involution on $\lie{sl}(n,\R)$ is given by negative transpose, i.e. $\theta X = - X^t$. The subalgebra $\lie{k}_0$ is then $\lie{so}(n,\R)$ and the ideal $\lie{p}_0$ is the space of symmetric matrices.

 For $\lie{su}(n)$ is a Cartan involution given by a negative conjugate transpose $\theta X = - \overline{X}^t$. The subalgebra $\lie{k}_0$ is the whole $\lie{su}(n)$ and $\lie{p}_0$ is of course empty.
\end{example}

We can generalize this as follows. Take a matrix Lie algebra, i.e. a subalgebra of $\lie{gl}(n,\C)$, that is closed under transposition and define $\theta X = -X^\dag$. Then
 \[
  \theta [X,Y] = -[X,Y]^\dag = - [Y^\dag,X^\dag] = [-X^\dag,-Y^\dag] = [\theta X, \theta Y]
 \]
 shows that $\theta$ is involution. Using the fact that $B$ is invariant with respect to automorphisms we get that
 \begin{align*}
  B_\theta(X,Y) &= -B(x,\theta Y) = - B(\theta X, \theta^2 Y) \\
                &= -B(\theta X, Y) = B_\theta(X,Y),
 \end{align*}
 which demonstrates that $B_\theta$ is symmetric. To show that it is also positive definite, we first need to show that for a scalar product $\langle X,Y \rangle = \Re (XY^\dag)$ we have that the adjoint of $\ad X$ is $\ad X^\dag$.
 \begin{align*}
  \langle [X,Y],Z \rangle &= \Re\tr (XYZ^\dag - YXZ^\dag) = \\
			  &= \Re\tr (YZ^\dag X - YXZ^\dag) =  \\% = \Re\tr (Y (Z^\dag X - X Z^\dag))\\
                          &= \Re\tr( Y(X^\dag Z - ZX^\dag)^\dag) = \langle Y, [X^\dag,Z] \rangle.
 \end{align*}
 Now we can show that $B_\theta$ is in fact positive definite as follows
 \begin{align*}
  B_\theta(X,X) &= -B(X,\theta X) = -\tr (\ad X \circ \ad \theta X )\\
                &= \tr (\ad X \circ \ad (X^\dag))  = tr (\ad X (\ad X)^*) \geq 0.
 \end{align*}

In fact, any real semisimple Lie algebra $\lie{g}_0$ is isomorphic to a Lie algebra of real matrices that is closed under transpose and the isomorphism can be chosen in such a way that the Cartan involution of $\lie{g}_0$ is carried to negative transpose (Proposition VI.6.28 of \cite{knapp}).

A Cartan involution $\theta$ of $\lie{g}_0$ yields an eigenspace decomposition $\lie{g}_0 = \lie{k}_0 \oplus \lie{p}_0$ of $\lie{g}_0$ into $+1$ and $-1$ eigenspaces of $\theta$. Since $\theta$ is a Lie algebra homomorphism, it follows that
\begin{equation}\label{eq:cartan_decomposition_1}
 [\lie{k}_0,\lie{k}_0] \subseteq \lie{k}_0, \quad[\lie{k}_0,\lie{p}_0] \subseteq \lie{p}_0, \quad [\lie{p}_0,\lie{p}_0] \subseteq \lie{k}_0.
\end{equation}
From these relations it is easy to derive that $\lie{k}_0$ and $\lie{p}_0$ are orthogonal with respect to $B_\theta$ and $B$. If $X$ is in $\lie{k}_0$ and $Y$ is in $\lie{p}_0$, then $\ad X \circ \ad Y $ sends $\lie{k}_0$ to $\lie{p}_0$ and $\lie{p}_0$ to $\lie{k}_0$; i.e. as a matrix in block form subordinated to the decomposition $\lie{g}_0 = \lie{k}_0 \oplus \lie{p}_0$ it has the form $\begin{smatrix} 0 & * \\ * & 0\end{smatrix}$. Thus it has trace $0$ and $B(X,Y) = 0$ and since $\theta Y = - Y$ also $B_\theta (X,Y) = 0$. Because $B_\theta$ is positive definite, the eigenspacese have the property that
\begin{equation}\label{eq:cartan_decomposition_2}
 B \text{ is } \begin{cases} \text{negative definite on } \lie{k}_0 \\ \text{positive definite on } \lie{p}_0. \end{cases}
\end{equation}

A decomposition of $\lie{g}_0 = \lie{k}_0 \oplus \lie{p}_0$ that satisfies \eqref{eq:cartan_decomposition_1} and \eqref{eq:cartan_decomposition_2} is called \emph{Cartan decomposition} of $\lie{g}_0$. Conversely any Cartan decomposition defines a Cartan involution by
\[
\theta =
 \begin{cases}
  + \Id \text{ on } \lie{k}_0 \\
  - \Id \text{ on } \lie{p}_0
 \end{cases}
\]
and we see that Cartan involutions are in bijective correspondence with Cartan decompositions.

Cartan involutions and decompositions can be even pushed to the Lie group level.
\begin{theorem}[Theorem VI.6.31 of \cite{knapp}]
 Let $G$ be a semisimple Lie group, let $\theta$ be a Cartan involution of its Lie algebra $\lie{g}_0$, let $\lie{g}_0 = lie{k}_0 \oplus \lie{p}_0$ be the corresponding Catan decomposition, and let $K$ be the analytic subgroup of $G$ with Lie algebra $\lie{k}_0$. Then
 \begin{enumerate}
  \item there exists a Lie group automorphism $\Theta$ of $G$ with differential $\theta$, and $\Theta^2=\Id$
  \item the subgroup of $G$ fixed by $\Theta$ is $K$
  \item the mapping $K\times \lie{p}_0 \to G$ given by $(k,X)\mapsto k \exp{X}$ is a diffeomorphism onto
  \item $K$ is closed and contains the center $Z$ of $G$
  \item $K$ is compact if and only if $Z$ is finite in which case it is a maximal compact subgroup of $G$.
 \end{enumerate}
\end{theorem}

This theorem justifies the following definition. We will call a real form $\lie{g}_0$ of $\lie{g}$ \emph{compact} if $\lie{g}_0 = \lie{k}_0$, i.e. if the Killing form $B$ is negative definite.

Take a Cartan decomposition $\lie{g}_0 = \lie{k}_0 \oplus \lie{p}_0$ and consider $\lie{g}_0$ as a subset of its complexification $\lie{g}$. Inspecting the signature of $B_\theta$ we easily see that $\lie{k}_0\oplus \imath \lie{p}_0$ is a compact form, say $\lie{u}_0$, of $\lie{g}$. Denote by $\sigma$ the conjugation of $\lie{g}$ with respect to the real form $\lie{g}_0$ and let $\tau$ denote the conjugation with respect to $\lie{u}_0$. Both $\sigma$ and $\tau$ are either $\Id$ or $-\Id$ on $\lie{k}_0, \imath \lie{k}_0, \lie{p}_0, \imath \lie{p}_0$. This immediately implies that the two involutions commute $\sigma \circ \tau = \tau \circ \sigma$. In particular $\tau (\lie{g}_0) \subseteq \lie{g}_0$ and the restriction of $\tau$ to $\lie{g}_0$ is the Cartan involution $\theta$ corresponding to the Cartan decomposition $\lie{g}_0=\lie{k}_0 \oplus \lie{p}_0$.

Conversely, given a compact form $\lie{u}_0$ of a complexification $\lie{g}$ of $\lie{g}_0$ such that the corresponding conjugations $\tau$ and $\sigma$ commute, we get a Cartan involution for $\lie{g}_0$ by restriction of the involution $\tau$ that corresponds to the compact form $\lie{u}_0$. Indeed, since $\lie{g}_0 \subseteq \lie{g} = \lie{u}_0 \oplus \imath \lie{u}_0$, we get for any $X+\imath Y\in\lie{g}_0$
\[
 B_\theta (X+\imath Y,X+\imath Y) = -B(X+\imath Y,X-\imath Y) = -B(X,X) - B(Y,Y),
\]
which is positive definite since $X,Y$ are elements from the compact Lie algebra $\lie{u}_0$.

A semisimple Lie algebra has up to inner isomorphism only one compact real form and it can be even shown that the compact form can be chosen in such a way that the corresponding conjugation $\tau$ commutes with any apriori chosen involution $\sigma$ of $\lie{g}$. This is the core of the proof of existence of Cartan involution for arbitrary real semisimple Lie algebra $\lie{g}_0$.

To summarize, if $\lie{g}_0 = \lie{k}_0 \oplus \lie{p}_0$ is a Cartan decomposition of $\lie{g}_0$, then $\lie{k}_0 \oplus \imath \lie{p}_0$ is a compact  real form of the complexification $\lie{g}$ of $\lie{g}_0$. Conversely, if $\lie{k}_0$ and $\lie{p}_0$ are the $+1$ and $-1$ eigenspaces of an involution $\sigma$ of $\lie{g}$ then $\sigma$ is Cartan involution if and only if the real form $\lie{k}_0 \oplus \imath \lie{p}_0$  is compact.

In the following we will use this simple lemma.
\begin{lemma}\label{lem:theta_adjoint}
 If $\lie{g}_0$ is a real semisimple Lie algebra and $\theta$ is a Cartan involution, then the adjoint operator to $\ad X$ with respect to $B_\theta$ is $-\ad \theta X$, i.e.
 \begin{equation*}
  (\ad X)^* = -\ad \theta X, \quad \forall X\in\lie{g}_0
 \end{equation*}
\end{lemma}
\begin{proof}
  We have for all $Y,Z\in\lie{g}$
  \begin{align*}
  B_\theta((\ad X)Y,Z) &= -B([X,Y],\theta Z) = B(Y,[X,\theta Z]) \\
                       &= B(Y,[\theta^2 X, \theta Z]) = B(Y,\theta [\theta X, Z]) \\
		       &= -B_\theta(Y,[\theta X,Z]) = B_\theta(Y,(-\ad \theta X)Z).
  \end{align*}
\end{proof}

In addition to compact form, there is always another real form (also unique up to conjugation) of a complex semisimple Lie algera $\lie{g}$. Let $\lie{h}_0$ be a Cartan subalgebra of $\lie{g}$ and consider its complexification $\lie{h}$ which is (by definition) a Cartan subalgebra of $\lie{g}$. We call a real Lie algebra $\lie{g}_0$ a \emph{split form} of $\lie{g}$ if the restrictions of elements of $\lie{h}^*$ to $\lie{h}_0$ are real valued.

To construct a split real form we can just take a suitable basis of $\lie{g}$ and its real span. In details, take a complex Lie algebra $\lie{g}$ and its Cartan subalgebra $\lie{h}$ and define $\lie{h}_0$ as the subset of $\lie{h}$ on which all the roots take only real values. There is always a choice (see Theorem VI.6.6 of \cite{knapp_advanced}) of root vectors $X_\alpha \in \lie{g}_\alpha$ such that $[X_\alpha, X_{-\alpha}] = H_\alpha$ and
\begin{gather*}
\beta \neq -\alpha \,\&\, \alpha + \beta \notin \roots \Longrightarrow [X_\alpha,X_\beta]=0 \\
 \alpha + \beta \in\roots \Longrightarrow [X_\alpha, X_\beta] = N_{\alpha,\beta}X_{\alpha+\beta},
\end{gather*}
where $N_{\alpha,\beta}\in\R$ and $N_{\alpha,\beta} = -N_{-\alpha,-\beta}$. Now the split form of $\lie{g}$ is obtained as
\[
 \lie{g}_\text{split} = \lie{h}_0 \oplus \bigoplus_{\alpha \in\roots} \R X_\alpha
\]
and a compact form of $\lie{g}$ can be then given as
\[
 \lie{k}_0 = \imath \lie{h}_0 \oplus \bigoplus_{\alpha\in\roots^+} \R (X_\alpha - X_{-\alpha}) \oplus \imath \R (X_\alpha + X_{-\alpha}).
\]

Let $\lie{g}_0$ be a real semisimple Lie algebra and let $\theta$ be its Cartan involution. A Cartan subalgebra $\lie{h}_0$ of $\lie{g}_0$ is called \emph{$\theta$-stable} if $\theta(\lie{h}_0)=\lie{h}_0$. In such a case we have $\lie{h}_0= (\lie{h}_0\cap\lie{k}_0) \oplus (\lie{h}_0\cap\lie{p}_0$, where $\lie{g}_0 = \lie{k}_0\oplus\lie{p}_0$ is the Cartan decomposition. We call the dimension of $\lie{h}_0\cap\lie{k}_0$ the \emph{compact dimension} of a $\theta$-stable  Cartan subalgebra $\lie{h}_0$ and similarly the dimension of $\lie{h}_0\cap\lie{p}_0$ is called the \emph{noncompact dimension} of $\lie{h}_0$. A $\theta$-stable Cartan subalgebra $\lie{h}_0 \leq \lie{g}_0$ is called \emph{maximally compact} or \emph{maximally noncompact} if and only if its compact (respectively noncompact) dimension is maximal possible.

%TODO theta stabilita, komplexni konjugace a akce thety (viz Vogan, mozna Knapp)

%\subsection{Iwasawa decomposition}
In contrast to the complex case, Cartan subalgebras of real Lie algebras are not unique up to conjugation. Up to conjugation by inner automorphism, there is a finite number of Cartan subalgebras and any Cartan subalgebra is conjugated via an inner automorphism to a $\theta$-stable Cartan subalgebra. Moreover there is up to conjugation by an element of $K$ only one maximally compact (or maximally noncompact) $\theta$-stable Cartan subalgebra of $\lie{g}_0$.

Let $\lie{g}$ be a complexification of $\lie{g}_0$ and let $\lie{h}$ be a complexification of a $\theta$-stable maximally noncompact Cartan subalgebra $\lie{h}_0$ of $\lie{g}_0$. Let $\sigma$ be a complex conjugation of $\lie{g}$ with respect to the real form $\lie{g}_0$. For $\alpha\in\roots$ we define $\sigma^* \alpha$ by $(\sigma^* \alpha) (H) = \overline{\alpha(\sigma H)}$ for all $H\in\lie{h}$. Since $\sigma$ is conjugate linear, $\sigma^*\alpha$ is again a complex linear form on $\lie{h}$ and identifying $\Hom_\C(\lie{h},\C)$ with $\Hom_\R(\lie{h}_0,\C)$, the map $\sigma^*$ coincides with complex conjugation. In fact, $\sigma^*$ is an involutive automorphism of the root system $\roots(\lie{g},\lie{h})$. A root $\alpha \in \roots(\lie{g},\lie{h})$ is called \emph{compact root} if $\sigma^*\alpha = -\alpha$. The set of compact roots is denoted by $\roots_c$.

\begin{proposition}[Proposition 2.3.8 of \cite{cap_parabolic_2009}]
 The set of compact roots is given by $\roots_c = \{ \alpha \in \roots \,:\,\alpha|\lie{a} = 0 \}$. It is an abstract root system on the Euclidean subspace of $\imath \lie{t}\oplus \lie{a}$ spanned by its elements. For $\alpha\in\roots_c$, the root space $\lie{g}_\alpha$ is contained in $\lie{k}\leq \lie{g}$.
\end{proposition}

%\subsection{Satake diagrams}

Choose a set of positive roots $\roots^+$ such that $\sigma^* \alpha \in \roots^+$ for all $\alpha\in\roots^+\setminus\roots_c$. One way to obtain such a system of positive roots is to choose ordering of $\roots$ by choosing a basis $\{H_1,\ldots, H_p\}$ of $\lie{a}$ and extending it to a basis $\{H_1,\ldots,H_r\}$ of $\imath\lie{t}\oplus\lie{a}$. By definition $\alpha\in\roots^+$ if and only if there is an index $j$ such that $\alpha(H_j) > 0$ and $\alpha(H_i) = 0 $ for all $i<j$. By definition $\alpha(H_i)\neq 0$ for some $i\leq p$ for $\alpha \in \roots^+\setminus \roots_c$ and since all $\alpha(H_j)$ are real, $\sigma H_i = H_i$ for $i\leq p$ and $\sigma(H_i) = -H_i$ for $i>p$.

Let $\sroots$ be the set of simple roots of $\roots^+$ and put $\sroots_c = \sroots \cap \roots_c$. Then $\sroots_c$ are a system of simple roots for $\roots_c$ and we order our system of simple roots $\sroots$ in such a way that elements of $\sroots_c$ come last. The following lemma is due to Ichir{o} Satake.
\begin{lemma}
\begin{enumerate}
 \item The element $\sigma^*\alpha - \alpha$ is not a root for any $\alpha\in\roots$.
 \item For $\alpha \in \sroots \setminus \sroots_c$, there is a unique element $\alpha'\in\sroots\setminus\sroots_c$ such that $\sigma^*\alpha-\alpha'$ is a linear combination of compact roots.
\end{enumerate}
\end{lemma}

The \emph{Satake diagram} of the real Lie algebra $\lie{g}_0$ is defined as follows. In the Dynkin diagram associated to the simple system $\sroots$, represent compact roots by a black dot and roots in $\sroots\setminus\sroots_c$ by a white dot. Moreover, for any $\alpha\in\sroots\setminus\sroots_c$ such that $\sigma^*\alpha\neq\alpha$, connect $\alpha$ by an arrow  to the unique simple root $\alpha'\in\sroots\setminus\sroots_c$ such that $\sigma^*\alpha -\alpha'$ is a linear combination of compact roots.



%\subsection{Parabolic subalgebras of real Lie algebras}

\begin{definition}[page 274, \cite{vogan}]
 Let $\lie{q}$ be a parabolic subalgebra of the complexification of a real semisimple Lie algebra $\lie{g}_0$ and let $\theta$ be the corresponding Cartan involution. We will call $\lie{q}$ to be $\theta$-stable if $\theta \lie{q} = \lie{q}$. It follows then that also the opposite parabolic subalgebra $\lie{q}^-$ is $\theta$-stable and that the Levi part is $\theta$-stable $\theta \lie{l} = \lie{l}$.
\end{definition}

For a real Lie algebra $\lie{g}_0$ we define $\lie{q}_0$ to be a parabolic subalgebra if and only if the complexification $\lie{q}$ is a parabolic subalgebra of the complexification $\lie{g}$. Similarly to the complex case, there is an equivalence between parabolic subalgebra $\lie{g}$ and gradings on $\lie{g}$ also in the real category. The standard parabolic subalgebras are given by crossed roots in Satake diagrams, where we are allowed to cross only white roots (i.e. those that are not in $\roots_c$.

%TODO rozepsat, real Iwasawa?s

\section{BGG category $\mathcal{O}$}

This chapter contains the description of Bernstein-Bernstein-Gelfand category $\mathcal{O}$ and a small recapitulation of Enright-Shelton equivalences which will be needed later.


\subsection{Generalized Verma modules and the Shapovalov form}


For any $\lambda\in\lie{h}^*$ we denote by $\C_\lambda$ the one dimensional representation of $\lie{h}$ on with character $\lambda$. We extend the action to $\lie{b}^- := \lie{n}^-\oplus\lie{h}$ by letting $\lie{n}^-$ act trivially. The \emph{Verma module} $N(\lambda)$ is then defined as $N(\lambda) := \lie{U(g)}\otimes_{\lie{U(b^-)}} \C_\lambda$. We will denote its highest weight vector by $v_\lambda$.

Let $\lambda$ be a $\Delta_c^+$ dominant and integral weight and denote by $F(\lambda)$ the finite dimensional irreducible $\lie{k}$-module.  We extend any irreducible representation of $K_\mathbb{C}$ to $P$ and to $\overline{P}$ by letting $\lie{p}_+$ and $\lie{p}_-$ act trivially. The \emph{generalized Verma module} $M(\lambda)$ is defined as $M(\lambda) = \lie{U}(\lie{g}) \otimes_{\lie{U}(\oppar)} F(\lambda)$. It is well known and easy to prove that $M(\lambda)$ contains a maximal nontrivial submodule $J(\lambda)$ and we denote by $L(\lambda)$ the corresponding irreducible quotient of $M(\lambda)$. Since the nilradical $\lie{p}_-$ of $\oppar$ is abelian and acts trivially on $F(\lambda)$, we have that $M(\lambda) \simeq S(\lie{p}_+)\otimes F(\lambda)$ as $K_\C$ representations, where $S(\lie{p}_+)$ is the symmetric algebra  over the Lie algebra $\lie{p}_+$.
%The canonical $\overline{P}$-invariant filtration of $M(\lambda) = \bigcup_{k\geq 0} M^k(\lambda)$ has filtration components $M^k(\lambda)= \{\epsilon^{i_1}\cdots\epsilon^{i_j}\otimes v\, | v \in F(\lambda), j \leq k \}$.
In the case of $M(\lambda)$, the geometric weight corresponds to the polynomial degree shifted by the weight of $F(\lambda)$.% and the canonical $\overline{P}$-invariant filtration is the same as the filtration induced by the geometric weight.

Let $\sigma$ be involutive antiautomorphism on $\lie{U(g)}$ such that it's restriction on the real form $\lie{g}_0$ is $-\id$. With our choice of Cartan subalgebra $\lie{h}$ we have that $\sigma: X_\beta \mapsto X_{-\beta}$ for $X_\beta \in \lie{g}_\beta$ and $\sigma: h_\alpha \mapsto h_\alpha$ for $h_\alpha \in \lie{h}$.

Let $P: \lie{U(g)} \to \lie{U(h)}$ be the projection defined by the splitting \[\lie{U(g)} = \lie{U(h)}\oplus \left( \lie{n_-U(g)} + \lie{U(g)n_+} \right)\]

\begin{definition}
  The \emph{universal Shapovalov form} on $\lie{U(g)}$ is defined as \[\langle u_1 , u_2 \rangle = P(\sigma(u_1)u_2).\] It is a bilinear form on $\lie{U(g)}$ with values in $\lie{U(h)} = S(\lie{h})$.

  For $\lambda\in\lie{h}^*$ we define the \emph{Shapovalov form on the Verma module} $N(\lambda)$ by \[\langle u_1 v_\lambda , u_2 v_\lambda \rangle = P(\sigma(u)v)(\lambda).\]
\end{definition}

It is easy to see that $\langle u\cdot v,v' \rangle = \langle v,\sigma(u)\cdot v' \rangle$ for all $v,v'\in M_\lambda$ and for all $u\in \lie{U(g)}$. Forms with such a property are called \emph{contravariant forms}.

The following proposition and its proof can be found e.g. in \cite{humphreys}.

\begin{proposition}
Contravariant forms have the following properties:
\begin{enumerate}
 \item If the $\lie{U(g)}$-module $M$ has a contravariant form $(v,v')_M$, then the weight spaces are orthogonal. I.e. $( M_\mu,M_\nu)=0$ whenever $\mu\neq\nu$ in $\lie{h}^*$.
 \item Suppose $M = \lie{U(g)} \cdot v$ is a highest weight module generated by a maximal vector $v$ of weight $\lambda$. If $M$ has a nonzero contravariant form, then the form is uniquely determined up to a scalar multiple by the (nonzero!) value $( v, v)_M$.
 \item  If $\lie{U(g)}$-modules $M_1, M_2$ have contravariant forms $(v, v')_{M_1}$ and $(w,w')_{M_2}$ , then $M := M_1\otimes M_2$ also has a contravariant form, given by \[(v\otimes w, v'\otimes w')_M := (v, v')_{M_1} (w,w')_{M_2}.\] In case both of the forms are nondegenerate, so is the product form.
 \item If $M$ has a contravariant form and $N$ is a submodule, the orthogonal complement $N^\perp := \{v\in M | (v, v')_M = 0 \text{ for all } v' \in N \}$ is also a submodule.
\end{enumerate}
\end{proposition}
\begin{proof}
\begin{enumerate}
 \item We use the fact that $\sigma(h) = h$ for $h\in\lie{h}$. Let $v$ be a vector of weight $\mu$ and let $v'$ be a vector of weight $\nu$. The for any $h\in\lie{h}$ we have
 \[
  \mu(h)(v,v')_M = (h\cdot v,v')_M = (v,\sigma(h)\cdot v')_M = (v,h\cdot v')_M = \nu(h)(v,v')_M.
 \]
 Since $v,v'$ were arbitrary we must have $(v,v')=0$ for $\mu\neq \nu$.
 \item In view of the already proven point it suffices to look at values of the form on a weight
space $M_\mu$. Typical vectors $v, v' \in M_\mu$ can be written as $u\cdot v, u'\cdot v$ for suitable $u, u'\in\lie{U(n)}$. Note that since $u$ takes $M_\lambda$ into $M_\mu$, the element $\sigma(u) \in \lie{U(n^-)}$ takes $M_\mu$ into $M_\lambda$ (which is spanned by $v$). Then $(v, v')_M = (u\cdot v, u'\cdot v)_M = (v, \sigma(u)u'\cdot v)_M$, which is a scalar multiple of $(v, v)_M$ depending just on the action of $\lie{U(g)}$ and not on the choice of the form.

The remaining points are elementary.
\end{enumerate}
\end{proof}

Important consequence of this is the following lemma.
\begin{lemma}
The maximal submodule of $N(\lambda)$ is the radical of the Shapovalov form.
\end{lemma}
\begin{proof}
Let $v\in J(\lambda)$  be arbitrary. Then $\langle v, v_\lambda \rangle = 0$ since clearly $v$ and $v_\lambda$ have different weights. Since $J(\lambda)^\perp$ is a submodule of $N(\lambda)$ containing the generating vector $v_\lambda$ the statement follows.
\end{proof}

The generalized Verma module $M(\lambda)$ is a quotient of the Verma module $N(\lambda)$. Hence the simple quotient $L(\lambda)$ of $M(\lambda)$ is also a quotient of $N(\lambda)$ by its maximal submodule. We get induced contravariant forms on $L(\lambda)$ and $M(\lambda)$  which we also call Shapovalov forms and we denote them by a same symbol.

\subsection{Category $\mathcal{O}$ and translation functors}

We present a short overview of translation functors as is presented in \cite{humphreys}. Since we deal with integral weights only, we omit all the notations that concerns nonintegral weights.

\begin{definition}
  Let $\lambda, \mu \in \weights$ be such that $\nu = \mu - \lambda \in \weights^+$ and consider a finite dimensional representation $F(\nu)$ of highest weight $\nu$. Then the translation functor $T_\lambda^\mu: \mathcal{O}_\mu \to \mathcal{O}_\lambda$ is defined by
  \[
   T_\lambda^\mu M := \proj(F(\nu)\otimes M),
  \]
  where $\proj$ is the projection from $\mathcal{O}$ to $\mathcal{O}_\mu$.
\end{definition}

The vector space $\lie{h}^*$ decomposes into so called facets for the affine Weyl group action according to decompositions of the set of positive roots $\roots^+$ as follows. The facet $F$ corresponding to $\roots^+ = \roots^+_- \cup \roots^+_0 \cup \roots^+_+$ is defined as the set of those $\lambda \in \lie{h}$ such that
\[
  \begin{cases}
   (\lambda + \rho, \alpha) < 0, & \forall \alpha \in \roots^+_- \\
   (\lambda + \rho, \alpha) = 0, & \forall \alpha \in \roots^+_0 \\
   (\lambda + \rho, \alpha) > 0, & \forall \alpha \in \roots^+_+.
  \end{cases}
\]

\begin{theorem}[Theorem 7.?? of \cite{humphreys}]\label{thm:translation}
 If two weights $\mu$ and $\lambda$ lie in the same facet, then the translation functors $T_\lambda^\mu$ and $T_\mu^\lambda$ implement an equivalence of categories between $\mathcal{O}_\mu$ and $\mathcal{O}_\lambda$.
\end{theorem}


\subsection{Equivalences of Enright and Shelton}

\section{Harish-Chandra modules and their globalizations}


\noindent Fix a maximal compact subgroup $K_{0}$ of $G_{0}$. Suppose we have
a linear action of $K_{0}$ on a complex vector space $M$. A vector $m\in M$
is called $K_{0}-$\emph{finite} if the span of the $K_{0}-$orbit of $m$ is
finite-dimensional and if the action of $K_{0}$ in this subspace is
continuous. The linear action of $K_{0}$ in $M$ is called $K_{0}-$\emph{%
finite }when every vector is $K_{0}-$finite. By definition, \emph{a
Harish-Chandra module} for $G_{0}$ is a finite length $\mathfrak{g}-$module $%
M$ equipped with a compatible, $K_{0}-$finite, linear action. One knows that
an irreducible $K_{0}-$module has finite multiplicity in a Harish-Chandra
module. For our purposes, it will also be useful to refer to a category of
\emph{good }$K_{0}-$modules. A \emph{good }$K_{0}-$module will mean a
locally finite module such that each irreducible $K_{0}-$module has finite
multiplicity therein.

\smallskip

\noindent A representation of $G_{0}$ in a complete locally convex
topological vector space $V$ is called \emph{admissible} if $V$ has finite
length (with respect to closed invariant subspaces) and if each irreducible $%
K_{0}-$module has finite multiplicity in $V$. When $V$ is admissible, then
each $K_{0}-$finite vector in $V$ is differentiable and the subspace of $%
K_{0}-$finite vectors is a Harish-Chandra module. The representation is
called \emph{smooth} if every vector in $V$ is differentiable. In this case,
$V$ is a $\mathfrak{g}-$module. For example, one knows that an admissible
representation in a Banach space is smooth if and only if the representation
is finite-dimensional.

\smallskip \smallskip

\noindent Given a Harish-Chandra module $M$, \emph{a globalization} $M_{%
\text{glob}}$ \emph{of }$M$ is an admissible representation of $G_{0}$ whose
underlying $(\mathfrak{g},K_{0})-$module of $K_{0}-$finite vectors is
isomorphic to $M$. By now, four canonical globalizations of Harish-Chandra
modules are known to exist. These are: the smooth globalization of Casselman
and Wallach \cite{C}, its dual (called: the distribution globalization),
Schmid's minimal globalization \cite{S} and its dual (the maximal
globalization). All four globalizations are smooth and functorial. In this
article we focus on the minimal and maximal globalizations of Schmid.

\smallskip \smallskip

\noindent The \emph{minimal globalization }$M_{\text{min}}$ of a
Harish-Chandra module $M$ is uniquely characterized by the property that any
$(\mathfrak{g},K_{0})-$equivariant linear of $M$ onto the $K_{0}-$finite
vectors of an admissible representation $V$ lifts to a unique, continuous $%
G_{0}-$equivariant linear map of $M_{\text{min}}$ into $V$. In particular, $%
M_{\text{min}}$ embeds $G_{0}-$equivariantly and continuously into any
globalization of $M$. The construction of the minimal globalization shows
that it's realized on a \emph{DNF space}. This means that its continuous
dual, in the strong topology, is a nuclear Frech\'{e}t space. One knows that
$M_{\text{min}}$ consists of analytic vectors and that it surjects onto the
analytic vectors in a Banach space globalization. Like each of the canonical
globalizations, the minimal globalization is functorially exact. In
particular, a closed $G_{0}-$invariant subspace of a minimal globalization
is the minimal globalization of its underlying Harish-Chandra module and a
continuous $G_{0}-$equivariant linear map between minimal globalizations has
closed range.

\smallskip

\noindent To characterize the maximal globalization, we introduce the $%
K_{0}- $finite dual on the category of Harish-Chandra modules. In
particular, let $M $ be a Harish-Chandra module. Then the algebraic dual $%
M^{\ast }$ of $M$ is a $\mathfrak{g}-$module and a $K_{0}-$module, but in
general not $K_{0}-$finite. We define $M^{\vee }$, \emph{the} $K_{0}-$\emph{%
finite (or Harish-Chandra) dual to} $M$, to be the subspace of $K_{0}-$%
finite vectors in $M^{\ast }$. Thus $M^{\vee }$ is a Harish-Chandra module.
In fact, the functor $M\mapsto M^{\vee }$ is exact on the category of good $%
K_{0}-$modules. We also have the formula
\begin{equation*}
\left( M^{\vee }\right) ^{\vee }\cong M\text{.}
\end{equation*}%
The maximal globalization $M_{\text{max}}$ of $M$ can be defined by the
equation%
\begin{equation*}
M_{\text{max}}=\left( \left( M^{\vee }\right) _{\text{min}}\right) ^{\prime }
\end{equation*}%
where the last prime denotes the continuous dual equipped with the strong
topology. In particular, $M_{\text{max}}$ is a globalization of $M$. Observe
that the maximal globalization is an exact functor, since all functors used
in the definition are exact. Because of the minimal property of $M_{\text{min%
}}$, it follows that any globalization of $M$ embeds continuously and
equivariantly into $M_{\text{max}}$. Note that the continuous dual of a
maximal globalization is the minimal globalization of the dual
Harish-Chandra module.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The problem is that $L(\lambda)$ is not a $P$-representation.  This is not surprising because the generalized Verma module $M(\lambda)$ was induced from a $\overline{P}$-representation. Let $L(\lambda)=\bigoplus_{\mu\in \widehat{K}_\C} L_\mu$ be the decomposition of $L(\lambda)$ into $K_\C$-types. Each $L_\mu$ is contained in some $S^k(\lie{p}_+,F(\lambda))$ modulo the maximal submodule of $M(\lambda)$ and the algebra $\lie{p}_+$ acts  as a multiplication by a variable, while $\lie{p}_-$ acts basically as a differentiation. To formalize this write $L(\lambda) = \bigoplus_{\mu\in\widehat{K_\C}, k\in\mathbb{N}} L_{\mu,k}$ where $L_{\mu,k}$ is the $K_\C$-type contained in $S^k(\lie{p}_+,F(\lambda))$ and note that $\lie{p}_+ (L_{\mu,k}) \subset L_{\mu,k+1}$.

The \emph{formal globalization} of $L(\lambda)$ is defined as   $\overline{L(\lambda)}=\prod_{\mu\in \widehat{K}_\C} L_\mu$ (product of topological vector spaces). (See e.g \cite{vogan_jr._unitary_2008}.) Since each $K_\C$-type is finite-dimensional and each $S^k(\lie{p}_+,F(\lambda))$ contains only finitely many irreducible $K_\C$-representations, we can write it as
\[\overline{L(\lambda)} = \prod_{k\in\mathbb{N}} L_k,\] %TODO predelat do lemmatu s dukazem?
where $L_k = \bigoplus_{\mu\in\widehat{K_c}} L_{\mu,k}$ is a finite sum. The action of $\lie{p}_+$ works as a right shift: $\lie{p}_+(L_k)\subset L_{k+1}$. The $(\lie{g},K)$-module $L(\lambda)$ can be realized as a space of polynomials with values in a finite dimensional $K$-representation $F_\lambda$ and it's formal completion can be thought of as a space of formal power series with values in $F_\lambda$. %TODO posledni vetu predelat do lematu s dukazem?

Now it is easy to see that the formal globalization  is a representation of $P$. The action of $\lie{p}_+$ on $\overline{L(\lambda)}$ integrates without any problems. Let $X$ be an arbitrary element of $\lie{p}_+.$ The exponential $u:=\exp(tX)v$ is defined for $v\in\overline{L(\lambda)}$ as usual by $\sum_{i=0}^\infty \frac{t^i}{i!} X^iv$. This is well defined for $v$ if and only if each component $u_\mu$ is well defined. If $u_\mu$ is contained in some $S^k(\lie{p}_+,F(\lambda))$, then it is a sum of at most $k$ elements of lower or equal geometric weight.



Let's consider a simple Lie group $G$ with a parabolic subgroup $P$, $\mathfrak{p} = \mathfrak{l}\oplus\mathfrak{n}$ and let $L$ be the Levi part of $P$ and $E\in \mathfrak{l}$ the grading element. Any simple highest weight representation  $\mathbb{V}$ of the pair $(\mathfrak{g},L)$ decomposes into eigenspaces of $\mathrm{ad}(E)$ and the same is true also for $\Lambda^k\mathfrak{n}\otimes\mathbb{V}$, $k\in \mathbb{N}$.

The formal completion of $\mathbb{V}$ is denoted by $\overline{\mathbb{V}}$ and can be defined e.g. as $\overline{\mathbb{V}} = (\mathbb{V}^\vee)^*$, where $\mathbb{V}^\vee$ is the $L$-finite submodule of the dual of $V$ (i.e. a nontwisted duality  in category $\mathcal{O}$). As $L$-representations we have

$$
\mathbb{V} = \bigoplus_i \mathbb{V}_i, \qquad \overline{\mathbb{V}}  = \prod_i \mathbb{V}_i
$$

and $\mathbb{V}$ is a $(\mathfrak{g},L)$-submodule of $\overline{\mathbb{V}}$.

\begin{proposition}
 Suppose that the Lie algebra homology and cohomology differentials are disjoint for $\mathbb{V}$, i.e. $\ker \delta \cap \im \delta^* = 0$ and $\ker \delta^* \cap \im \delta = 0$. We state that differentials are still disjoint for the formal completion of $\mathbb{V}$. Moreover, if the homology (or equivalently cohomology) of $\mathbb{V}$ is finite-dimensional, then it is equal to the cohomology of the formal completion.
\end{proposition}

\begin{proof}

Elements of the formal completion (of an infinite-dimensional module) $\mathbb{W}$ can be written as infinite tuples of elements of $\mathbb{W}$
$$
u\in\overline{\mathbb{W}} \leftrightarrow u = (u_i)_{i\in I},
$$
where the index set $I$ runs over all eigenvalues of the action of $E$ on $\mathbb{W}$. And a formal completion of $ \Lambda^k \mathfrak{n} \otimes \mathbb{V}$ is  $\Lambda^k \mathfrak{n}  \otimes \overline{\mathbb{V}}$.

For a contradiction, suppose that there is nonzero $u$ in $\ker \delta \cap \im \delta^*$. Without a loss of generality, we can consider $u$ to be an element of the $k$-th chain space. Let's denote this $k$-th chain space  $\Lambda^k\otimes \mathbb{V}$ by $\mathbb{W}$ Since $u$ is nonzero, there must exists $i$ such that $u_i\neq 0$. Both differentials are natural, which means that they commute with restriction from $\overline{\mathbb{W}}$ to $\mathbb{W}$. They are moreover $L$-invariant, which in particular means that they commute with the action of the grading element, which means that they act component-wise on $(u_i)_{i \in I}$. It follows that if we take $\widetilde{u}= (\widetilde{u_j})\in \mathbb{W} \subseteq \overline{\mathbb{W}}$ to be zero  for $j\neq i$ and $\widetilde{u_i} = u_i$, then we have $\delta \widetilde{u} = 0$.  Since $u\in \im \delta^*$, there must exists a $v\in\overline{\mathbb{W}}$ such that $\delta^* v = u$ and we can define in the same way as before a $\widetilde{v}\in\mathbb{W}$
such that $\delta^* \widetilde{v} = \widetilde{u}$. Thus we see that there is a non-zero element in $\ker \delta \cap \im \delta^*\cap \Lambda^k\otimes \mathbb{W}$. This is a contradiction with the assumption that $\delta$ and $\delta^*$ are disjoint for $\mathbb{V}$.


Basically, the same argument proves that the cohomology must stay the same if it is finite-dimensional. From the Hodge theory (which is implied by the disjointness) we know that any element of the cohomology group can be uniquely represented by an alement in $\ker (\delta + \delta^*)$. Let $D=\delta + \delta^*$ and suppose for a contradiction that there is a nonzero element $(u_i)$ in $\ker D \setminus \ker D_{|\mathbb{W}}$, where $\mathbb{W}$ is the $k$-th chain space of $\mathbb{V}$. Pick $i_0$ such that $u_{i_0} \neq 0$ and $i_0$ is bigger than any eigenvalue of $E$ on $\ker D_{|\mathbb{W}}$.\footnote{This is well defined because of the finite-dimensionality of $\ker D_{|\mathbb{W}}$.} Since $D$ is again $L$ invariant we proceed as before and construct $\widetilde{u}\in\mathbb{W}\cap\ker D$. The choice of $i_0$ now leads to the desired contradiction.

\end{proof}

Hodge theory for nilpotent (co)homoloy was invented by Kostant in \cite{kostant_lie_1961}.

\section{Cohomology and homology of Lie algebras}

In this section we denote by $\lie{m}$ an arbitrary Lie algebra and by $\rep{V}$ its representation. We will denote the action of $\lie{m}$ on $\rep{V}$ by a dot.

The chain spaces of \emph{Lie algebra homology} $C_k(m,\rep{V})$ of the algebra $\lie{m}$ with values in $\rep{V}$ are defined as $\Lambda^k\lie{m}\otimes\rep{V}$. The Lie algebra \emph{homology differential} \[\lhd_\lie{m} : C_{k+1}(\lie{m},\rep{V}) \to C_k(\lie{m},\rep{V})\] is defined by the following formula
\begin{multline*}
\lhd_\lie{m} (Z_0\wedge\cdots Z_k\otimes v) = \sum_{i=0}^k (-1)^{i+1} Z_0\wedge\cdots\wedge\widehat{Z_i}\wedge\cdots\wedge Z_k\otimes Z_i\cdot v\,  + \\
				      +\sum_{i<j} (-1)^{i+j} [Z_i,Z_j]\wedge Z_0\wedge\cdots\wedge\widehat{Z_i}\wedge\cdots\wedge\widehat{Z_j}\wedge\cdots\wedge Z_k\otimes v,
\end{multline*}
where $Z_i\in\lie{m}$ for $i=0,\ldots,k$. If the algebra $\lie{m}$ is abelian, then the second term in the sum is zero.

The cochain spaces of \emph{Lie algebra cohomology} $C^k(\lie{m},\rep{V})$ are defined as $\Hom(\Lambda^k \lie{m},\rep{V})$. The Lie algebra \emph{cohomology differential} \[\lcd_\lie{m} :  C^k(\lie{m},\rep{V}) \to C^{k+1}(\lie{m},\rep{V})\] is defined as
\begin{multline*}
 (\lcd_\lie{m} \phi)(X_0,\ldots, X_n) = \sum_{i=0}^n (-1)^i X_i \cdot \phi(X_0,\ldots,\widehat{X_i},\ldots, X_n)\, + \\
				+\sum_{i<j} (-1)^{i+j} \phi([X_i,X_j],X_0,\ldots,\widehat{X_i},\ldots,\widehat{X_j},\ldots,X_n),
\end{multline*}
where $X_0,\ldots, X_n \in \lie{m}$ and $\phi:\Lambda^k \lie{m} \to \rep{V}$. Again, we can forget the second term if the algebra $\lie{m}$ is commutative.

There is a natural identification of $C_k(\lie{m}^*,\rep{V})$ and $C^k(\lie{m},\rep{V})$ coming from the natural isomorphism $\Lambda^k \lie{m}^* \otimes \rep{V} \simeq \Hom(\lie{m},\rep{V})$.

We can identify $C^k(\lie{p}_-,\rep{V})=\Hom (\Lambda^k\lie{p}_-,\rep{V})$ with $\Lambda^k {\lie{p}_-}^*\otimes\rep{V}$. Since the Killing form induces an isomorphism ${\lie{p}_-}^* \simeq \lie{p}_+$, we can consider the Lie algebra cohomology differential $\lcd$ as an operator on the chain spaces of Lie algebra homology $\lcd: \Lambda^k {\lie{p}_-}^* \otimes V \to \Lambda^{k+1}{\lie{p}_-}^*\otimes V$. After these identifications we get the formula
\[
 \lcd  (Z_1\wedge\cdots\wedge Z_k\otimes v) = \sum_{i=1}^{2p} \epsilon^i \wedge Z_1\wedge\cdots\wedge Z_k\otimes e_i\cdot v.
\] The Lie algebra cohomology differential is $\overline{P}$-equivariant. In particular, both $\lcd$ and $\lhd$ are $K_\C$-equivariant and consequently they preserve the geometric weight.

The Kostant Laplacian is defined on each $C_k(\lie{p}_+,\rep{V})$ as $\lap = \lhd \lcd + \lcd \lhd$. It was proven in \cite{kostant_lie_1961} that for a finite-dimensional $\lie{g}$-representation $\rep{V}$ there is a positive definite scalar product on $C_\bullet(\lie{p}_+,\rep{V})$ with respect to which are $\lcd$ and $\lhd$ adjoint. It follows that there is a direct sum \emph{Hodge decomposition} of $K_\C$-modules $C_\bullet(\lie{p}_+,\rep{V})=\im \lcd \oplus  \ker \lap \oplus \im \lhd$ and moreover $\ker \lhd = \ker \lap \oplus \im \lhd$ and $\ker \lcd = \ker \lap \oplus \im \lcd$. It follows that $H_\bullet(\lie{p}_+,\rep{V})\simeq \ker \lap \simeq H^\bullet(\lie{p}_-,\rep{V})$.

%\subsection{Invariant and coinvariant functors and their derivations}

\noindent \emph{The right standard resolution of }$\mathbb{C}$ is the
complex of free right $U(\mathfrak{n})-$modules given by
\begin{equation*}
\cdots \rightarrow \Lambda ^{p+1}\mathfrak{n}\otimes U(\mathfrak{n}%
)\rightarrow \Lambda ^{p}\mathfrak{n}\otimes U(\mathfrak{n})\rightarrow
\cdots \rightarrow \mathfrak{n}\otimes U(\mathfrak{n})\rightarrow U(%
\mathfrak{n})\rightarrow 0\text{.}
\end{equation*}%
Applying the functor
\begin{equation*}
-\otimes _{U(\mathfrak{n})}M\text{ }
\end{equation*}%
to the standard resolution we obtain a complex
\begin{equation*}
\cdots \rightarrow \Lambda ^{p+1}\mathfrak{n}\otimes M\rightarrow \Lambda
^{p}\mathfrak{n}\otimes M\rightarrow \cdots \rightarrow \mathfrak{n}\otimes
M\rightarrow M\rightarrow 0
\end{equation*}%
of left $\mathfrak{l}-$modules called \emph{the standard} $\mathfrak{n}-$%
\emph{homology complex}. Here $\mathfrak{l}$ acts via the tensor product of
the adjoint action on $\Lambda ^{p}\mathfrak{n}$ with the given action on $M$%
. Since $U(\mathfrak{g})$ is free as $U(\mathfrak{n})-$module, a routine
homological argument identifies the pth$-$homology of the standard complex
with the pth $\mathfrak{n}-$homology group
\begin{equation*}
H_{\text{p}}(\mathfrak{n},M).
\end{equation*}%
One knows that the induced $\mathfrak{l}-$action on the homology groups of
the standard complex is the correct one.

\smallskip

\noindent The \emph{zero} $\mathfrak{n}-$\emph{cohomology }of a $\mathfrak{g}%
-$module $M$ is the $\mathfrak{l}-$module
\begin{equation*}
H^{0}(\mathfrak{n},M)=\text{Hom}_{U(\mathfrak{n})}(\mathbb{C},M).
\end{equation*}%
This determines a left exact functor from the category of $\mathfrak{g}-$%
modules to the category of $\mathfrak{l}-$modules. By definition, \emph{the}
$\mathfrak{n}-$\emph{cohomology groups of} $M$ are the $\mathfrak{l}-$%
modules obtained as the corresponding derived functors. These $\mathfrak{l}-$%
modules can be calculated by applying the functor
\begin{equation*}
\text{Hom}_{U(\mathfrak{n})}(-,M)
\end{equation*}%
to the standard resolution of $\mathbb{C}$, this time by free left $U(%
\mathfrak{n})-$modules. In a natural way, one obtains a complex of $%
\mathfrak{l}-$modules and pth cohomology of this complex realizes the pth $%
\mathfrak{n}-$cohomology group

\begin{equation*}
H^{\text{p}}(\mathfrak{n},M).
\end{equation*}

\noindent Let $\mathfrak{n}^{\ast }$denote the $\mathfrak{l}-$module dual to
$\mathfrak{n}$. Then, using the standard complexes and the natural
isomorphism of $\mathfrak{l}-$modules
\begin{equation*}
\Lambda ^{p}\mathfrak{n}^{\ast }\otimes M\cong \text{Hom}(\Lambda ^{p}%
\mathfrak{n},M)
\end{equation*}%
one can deduce the following well known fact \cite[Section 2]{HS}:

\begin{proposition}
Suppose $M$ is a $\mathfrak{g-}$module. Let $\mathfrak{p}\subseteq \mathfrak{%
g}$ be a parabolic subalgebra with nilradical $\mathfrak{n}$ and Levi factor
$\mathfrak{l}$. \newline
(a) Let $M^{\ast }$ denote the $\mathfrak{g}-$module dual to $M.$ Then there
is a natural isomorphism
\begin{equation*}
H_{\text{p}}(\mathfrak{n},M^{\ast })\cong H^{\text{p}}(\mathfrak{n},M)^{\ast
}
\end{equation*}%
where $H^{\text{p}}(\mathfrak{n},M)^{\ast }$ denotes the $\mathfrak{l-}$%
module dual to $H^{\text{p}}(\mathfrak{n},M)$.\newline
(b) Let d denote the dimension of $\mathfrak{n}$. Then there is a natural
isomorphism
\begin{equation*}
H_{\text{p}}(\mathfrak{n},M)\cong H^{\text{d-p}}(\mathfrak{n},M)\otimes
\Lambda ^{\text{d}}\mathfrak{n}\newline
\end{equation*}
\end{proposition}



%\subsection{Real versus complex}

\begin{proposition}[Proposition 3.3.6 of \cite{cap_parabolic_2009}]
 Let $\lie{g}$ be a $|k|$-graded semisimple Lie algebra with complexification $\lie{g}^\C$ and let $\rep{V}$ be a complex representation of $\lie{g}$. Then the real cohomology spaces $H^*(\lie{g}_-,\rep{V})$ are 	naturally complex vector spaces and we have a natural isomorphism of $\lie{g}_0$-modules
 \[
  H_\R^*(\lie{g}_-,\rep{V}) \simeq H_\C^*(\lie{g}_-^\C,\rep{V}).
 \]

\end{proposition}


\subsection{Disjoint operators and Hodge decomposition}

Let $V$ be a topological vector space and let $\lcd$ and $\lhd$ be two linear operators on $V$ such that $\lcd^2 = \lhd^2 = 0$. Such operators are called \emph{disjoint} if
\begin{gather*}
 \lcd\lhd x= 0 \text{ implies } \lhd x =0 \\
 \intertext{and}
 \lhd \lcd x = 0 \text{ implies } \lcd x = 0
\end{gather*}
for all $x\in V$. In other words, $\lhd$ and $\lcd$ are disjoint if and only if
\begin{equation}\label{eq:disjointness}
 \ker \lcd \cap \im \lhd = 0 \quad \& \quad \ker \lhd \cap \im \lcd = 0.
\end{equation}

%TODO Co zkusit pozadovat, aby $V=\im\lhd \oplus \ker \lcd$ a vice versa?

The \emph{laplacian} is then defined as
\[\lap = \lcd \lhd + \lhd \lcd.\] We note that $\lap  = (\lhd + \lcd)^2$ and hence one can consider $\lhd + \lcd$ as the Dirac operator for the laplacian $\lap$. %See the book \cite{huang} for investigations of this Dirac operator.

\begin{proposition}%[Proposition 2.1 of \cite{kostant_lie_1961}]
 Let the notation be as above and assume $\lcd$ and $\lhd$ are disjoint and $\dim V < \infty$. Then
 \begin{equation}\label{eq:hodge_decomp_aux}
  \ker \lap = \ker \lcd \cap \ker\lhd \quad \& \quad  \im \lap = \im \lhd \oplus \im \lcd.
 \end{equation}
 Also one has a direct sum decomposition (\emph{Hodge decomposition}),
 \begin{equation}\label{eq:hodge_decomp}
    V = \im \lcd \oplus \ker \lap \oplus \im \lhd.
 \end{equation}
\end{proposition}
\begin{proof}
To prove the first equality of \eqref{eq:hodge_decomp_aux} we just use the definition of disjointness \eqref{eq:disjointness} of $\lhd$ and $\lcd$. The inclusion $\ker \lhd \cap \ker \lcd \subseteq \ker\lap$ is trivial. Let $x \in \ker \lap$ and put $y=-\lhd\lcd x$. Then $\lhd y =0$ and also $y =\lcd\lhd x$. Thus $\lhd\lcd\lhd x = 0$ and by disjointness this implies that $\lcd\lhd x = 0$ which, for the same reason, implies $\lhd x = 0$. Similarly $\lcd x = 0$. The remaining two decompositions of \eqref{eq:hodge_decomp_aux} are direct consequence of $\ker\lap = \ker\lhd\cap\ker\lcd$ and of disjointness of $\lhd$ and $\lcd$.

 It is obvious that $\im \lap \subseteq \im \lcd + \im \lhd$ and  by \eqref{eq:hodge_decomp_aux} and disjointness \eqref{eq:disjointness} we have $(\im \lhd + \im \lcd) \cap \ker \lap = 0$. If follows that $\im \lap \cap \ker \lap =0$. Since $V$ is finite-dimensional, we get $\dim \ker\lap + \dim \im \lap = \dim V$ and \eqref{eq:hodge_decomp}  and the second equality of \eqref{eq:hodge_decomp_aux} follows.
\end{proof}

\begin{corollary}
 Under the assumptions of the previous proposition, there are decompositions
  \begin{equation}
    \quad \ker \lhd = \im \lhd \oplus \ker \lap, \quad \ker \lcd = \im\lcd\oplus\ker\lap.
  \end{equation}
  Consequently we have isomorphisms
  \begin{equation}\label{eq:kerlap_iso}
    \ker \lap \simeq \ker \lcd /\im \lcd \quad\&\quad \ker \lap \simeq \ker \lhd / \im \lhd
  \end{equation}
  given by restriction to $\ker \lap$ of the canonical mappings $\ker \lcd \to \ker \lcd / \im \lcd$ and $\ker \lhd \to \ker \lhd / \im \lhd$.
\end{corollary}
\begin{proof}
 This is a direct consequence of the Hodge decomposition \eqref{eq:hodge_decomp}.
\end{proof}

\begin{remark}
 For any two linear mappings $\lhd$ and $\lcd$ on a vector space $V$ such that $\im\lhd\cap\im\lcd = 0$ we have that \[ \ker (\lhd + \lcd)  = \ker \lhd \cap \ker \lcd.\] Under our assumptions we get that $\ker (\lhd +\lcd) = \ker \lap$, since $\im \lhd \subseteq \ker \lhd$ and by disjointness \eqref{eq:disjointness} $\im \lhd \cap \im \lcd = 0$.
\end{remark}


For better understanding of how our operators act we represent them in a block matrix form with respect to the Hodge decomposition \eqref{eq:hodge_decomp}
\[
 \lcd = \begin{pmatrix} 0 & 0 & A\\0&0&0\\0&0&0\end{pmatrix} \quad \lhd = \begin{pmatrix} 0 & 0 &0\\0&0&0\\ B&0&0\end{pmatrix} \quad
 \lap = \begin{pmatrix}
	  AB & 0 & 0 \\
	  0 & 0 & 0 \\
	  0 & 0 & BA
	\end{pmatrix},
\]
where $A$ is the restriction of $\lcd$ to $\im\lhd$ and $B$ is the restriction of $\lhd$ to $\im \lcd$.

There is a convenient way to construct pairs of disjoint operators.
\begin{proposition} %TODO jak je to s im adjungovaneho operatoru? v konecne dimenzi by ta podminka na nedegenerovanost na im adjunktu mela byt nadbytecna. v nekonecne?
 Let $\lhd$ be a differential on a vector space $V$ endowed with a non-degenerate bilinear (respectively sesquilinear) form $\langle \, , \, \rangle$ and let $\lcd$ be the adjoint of $\lhd$ with respect to $\langle \, , \, \rangle$. If the restriction of $\langle \, , \, \rangle$ to $\im \lhd$ and $\im \lcd$ are non-degenerate, then $\lhd$ and $\lcd$ are disjoint and the Hodge decomposition \eqref{eq:hodge_decomp} is orthogonal with respect to $\langle \, , \, \rangle$.
\end{proposition}
\begin{proof}
 It is trivial to see that $\lcd$ is a differential, for we have 
 \[ 0 = \langle \lhd ^2 x, y \rangle = \langle x, \lcd^2 y \rangle\]
 for all $x,y\in V$.

 To prove \eqref{eq:disjointness}, let $x\in V$ be such that $\lhd \lcd x = 0$. We get
 \[ 0 = \langle \lhd\lcd x , y \rangle = \langle \lcd x, \lcd y \rangle \]
 for all $y\in V$. By our assumptions is the bilinear (resp. sesquilinear) map $(x,y) \to \langle \lcd x, \lcd y \rangle$ non-degenerate and hence we conclude that $\lcd x = 0$. Exchanging the roles of $\lhd$ and $\lcd$ in this computation we get that also $\lcd \lhd x =0$ implies $\lhd x=0$.

 Orthogonality of the Hodge resolution follows from $\ker \lhd = (\im\lcd)^\perp$ and $\ker \lcd = (\im \lhd)^\perp$.
\end{proof}
\begin{corollary}
 Let $V$ be endowed with a scalar product $\langle \, , \, \rangle$ and a differential $\lhd$. Let $\lcd$ be the adjoint of $\lhd$. Then $\lhd$ and $\lcd$ are disjoint operators. 
\end{corollary}
\begin{proof}
 This is trivial as the restriction of $\langle \, , \, \rangle$ to any subspace is non-degenerate.
\end{proof}

 If $V$ is infinite-dimensional and $L$ is any closed subspace of finite codimension, then any algebraic complementary subspace to $L$ in $V$ is also a topological complement (\cite{schaefer}). We further impose on $\lhd$ and $\lcd$ that the are continuous with closed image\footnote{We note that for a finite-dimensional vector space $V$ are these topological conditions automatically satisfied for all linear operators.}


%\subsection{Hodge decompositions and Kostant's theorem}
%TODO konecne rozmerny pripad

\begin{definition}
A real parabolic subalgebra (of some real form of $\lie{g}$, possibly different from $\lie{g}_0$) $\lie{q}_0$ is  \emph{admissible}, if it's complexification $\lie{q}$ is  $\theta$-stable,\footnote{Parabolic subalgebra $\lie{q}$ is $\theta$-stable iff $\lie{q}\cap\overline{\lie{q}}=\lie{l}$ and $\theta \lie{q}=\lie{q}$.} where $\theta$ is the Cartan involution associated to the real form $\lie{g}_0$ and for $\lie{q}=\lie{l}\oplus\lie{u}_+$ it holds that $\lie{l}\subseteq \lie{k}$ and $\lie{p}_+\subseteq\lie{u}_+$.
\end{definition}

The authors of \cite{huang_dirac_2006} proved that if $\rep{V}$ is a unitarizable $(\lie{g},K)$-module and $\lie{u}_+$ is the nilradical of an admissible real Lie algebra, then the Hodge decomposition of $C_\bullet(\lie{u}_+,\rep{V})$ is still valid. We compute several explicit examples in the next chapter. %TODO pridat odkaz na kapitolu

The article \cite{boe_kostant_2009} provides classification of simple modules in certain parabolic BGG categories $\mathcal{O}_S$. The classification is given by subdiagrams of the Dynkin diagram. The proof of Theorem \ref{thm:cohomology} is based on an equivalence of categories given in \cite{enright_categories_1987}. This equivalences relate the relevant blocks in $\mathcal{O}_S$ to blocks for a lower rank algebras. In this way the unitarizable highest weight modules correspond to finite-dimensional ones for which the Kostant formula is known. It also follows that the structure of the resolutions is preserved. The Table \ref{tbl:sing}, taken from \cite{boe_kostant_2009}, shows the relevant information. 

Let $J$ denote the set of singular simple roots, i.e. \[J= \{ \alpha \in \roots^0 | (\lambda+\rho,\check{\alpha}) = 0 \}.\] The columns $\alpha$ and $\alpha'$ give the crossed roots in the Dynkin diagrams. Each Kostant module\footnote{These are the modules $M$ in $\mathcal{O}$ for which there's is a combinatorial formula for $H^i(\lie{p}_-,M)$ of certain type. The unitarizable highest weight modules are Kostant modules according to \cite{davidson_differential_1991}. For details see \cite{boe_kostant_2009}.} corresponds to a connected subdiagram of $\mathcal{D}'$ containing $\alpha'$. Each such subdiagram gives a parabolic pair and the Kostant modules correspond to finite-dimensional modules for the semisimple part of the Levi factor of $\mathcal{D}'$.

\begin{table}[h] 
%\begin{center}
\begin{tabular}{cccccc}
$\mathcal{D}$ &  $\alpha$ & $|J|$ & $\mathcal{D}'$ & $\alpha'$    \\[2pt] \hline 
$(A_n,A_{r-1}\times A_{n-r})$ & $\a_r$   & $t$ & $(A_{n-2t},A_{r-t-1}\times A_{n-r-t})$ & $\a_{r-t}$ \\
$(B_n,B_{n-1})$ & $\alpha_1$   & 1 (short) & $\varnothing$  & --  \\
$(B_n,B_{n-1})$ & $\a_1$   & 1 (long) & $\varnothing$ & --  \\
$(C_n,A_{n-1})$ & $\a_n$   & $t$ (all short) & $(D_{n+1-2t},A_{n-2t})$  & $\a_{n+1-2t}$  \\
$(C_n,A_{n-1})$ & $\a_n$   & $t$ (1 long) & $(D_{n+1-2t},A_{n-2t})$  & $\a_{n+1-2t}$ \\
$(D_n,D_{n-1})$ & $\a_1$   & 1 & $(A_1,\varnothing)$  & $\a_1$  \\
$(D_n,D_{n-1})$ & $\a_1$   & 2 ($\{n-1,n\}$) & $\varnothing$  & --   \\
$(D_n,A_{n-1})$ & $\a_n$   & $t$ & $(D_{n-2t},A_{n-2t-1})$  & $\a_{n-2t}$  \\
$(E_6,D_5)$ & $\a_6$   & 1 & $(A_5,A_4)$  & $\a_5$ \\
$(E_6,D_5)$ & $\a_6$   & 2 & $\varnothing$  & --  \\
$(E_7,E_6)$ & $\a_7$   & 1 & $(D_6,D_5)$  & $\a_1$   \\
$(E_7,E_6)$ & $\a_7$   & 2 & $(A_1,\varnothing)$  & $\a_1$  \\
$(E_7,E_6)$ & $\a_7$   & 3 ($\{2,5,7\}$) & $\varnothing$  & --   \\[2pt] \hline
\end{tabular}
\medskip
\caption{Data for singular Hermitian symmetric categories}\label{tbl:sing}
%\end{center}
\end{table}

